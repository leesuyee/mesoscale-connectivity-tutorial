{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8oQInG8SLTBja2odhz4pO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leesuyee/connectivity-edu-tutorial/blob/main/mesoscale_connectivity_coding_activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**\n",
        "\n",
        "Run the cell below to pip install the necessary packages. After install, restart the session and start at the next cell.\n",
        "\n",
        "## **DO NOT RERUN THIS CELL**\n",
        "\n"
      ],
      "metadata": {
        "id": "8VJzJHQS-28c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install s3fs lxml pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg2M2XES3w9e",
        "outputId": "3e53832a-fd19-40b3-c237-53f5f0e31f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: s3fs in /usr/local/lib/python3.12/dist-packages (2026.1.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: aiobotocore<4.0.0,>=2.5.4 in /usr/local/lib/python3.12/dist-packages (from s3fs) (3.1.1)\n",
            "Requirement already satisfied: fsspec==2026.1.0 in /usr/local/lib/python3.12/dist-packages (from s3fs) (2026.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from s3fs) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<4.0.0,>=2.5.4->s3fs) (0.13.0)\n",
            "Collecting botocore<1.42.31,>=1.41.0 (from aiobotocore<4.0.0,>=2.5.4->s3fs)\n",
            "  Using cached botocore-1.42.30-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<4.0.0,>=2.5.4->s3fs) (1.1.0)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<4.0.0,>=2.5.4->s3fs) (6.7.0)\n",
            "Requirement already satisfied: wrapt<3.0.0,>=1.10.10 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<4.0.0,>=2.5.4->s3fs) (2.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.15.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.31,>=1.41.0->aiobotocore<4.0.0,>=2.5.4->s3fs) (2.5.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.11)\n",
            "Using cached botocore-1.42.30-py3-none-any.whl (14.6 MB)\n",
            "Installing collected packages: botocore\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.42.33\n",
            "    Uninstalling botocore-1.42.33:\n",
            "      Successfully uninstalled botocore-1.42.33\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "boto3 1.42.33 requires botocore<1.43.0,>=1.42.33, but you have botocore 1.42.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed botocore-1.42.30\n",
            "Requirement already satisfied: aind-data-access-api==1.2.1 in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from aind-data-access-api==1.2.1) (2.32.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (from aind-data-access-api==1.2.1) (1.42.33)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from aind-data-access-api==1.2.1) (2.12.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.0 in /usr/local/lib/python3.12/dist-packages (from aind-data-access-api==1.2.1) (2.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->aind-data-access-api==1.2.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->aind-data-access-api==1.2.1) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->aind-data-access-api==1.2.1) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->aind-data-access-api==1.2.1) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.0->aind-data-access-api==1.2.1) (1.2.1)\n",
            "Collecting botocore<1.43.0,>=1.42.33 (from boto3->aind-data-access-api==1.2.1)\n",
            "  Using cached botocore-1.42.33-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3->aind-data-access-api==1.2.1) (1.1.0)\n",
            "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3->aind-data-access-api==1.2.1) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->aind-data-access-api==1.2.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->aind-data-access-api==1.2.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->aind-data-access-api==1.2.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->aind-data-access-api==1.2.1) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.33->boto3->aind-data-access-api==1.2.1) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.33->boto3->aind-data-access-api==1.2.1) (1.17.0)\n",
            "Using cached botocore-1.42.33-py3-none-any.whl (14.6 MB)\n",
            "Installing collected packages: botocore\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.42.30\n",
            "    Uninstalling botocore-1.42.30:\n",
            "      Successfully uninstalled botocore-1.42.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "aiobotocore 3.1.1 requires botocore<1.42.31,>=1.41.0, but you have botocore 1.42.33 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed botocore-1.42.33\n",
            "\u001b[31mERROR: Invalid requirement: '==': Expected package name at the start of dependency specifier\n",
            "    ==\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import s3fs\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class load_data:\n",
        "    \"\"\"\n",
        "    Minimal Colab-compatible loader for SmartSPIM data (CCF coordinates and region counts) streamed directly from S3\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mouse_ID : str | int\n",
        "        Mouse ID (e.g. 689305)\n",
        "\n",
        "        bucket : str\n",
        "        S3 bucket name (e.g. \"s3://aind-open-data\")\n",
        "\n",
        "        anon : bool\n",
        "        Whether to use anonymous credentials (e.g. True)\n",
        "\n",
        "        prefer_stitched : bool\n",
        "        Whether to prefer stitched data (e.g. True)\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    rootDir : str\n",
        "        Resolved S3 path to the selected SmartSPIM dataset.\n",
        "\n",
        "    quantPaths : dict[str, str]\n",
        "        Mapping from imaging channel (e.g., ``\"488\"``) to the\n",
        "        corresponding ``cell_count_by_region.csv`` file path.\n",
        "\n",
        "    ccfCellsPaths : dict[str, str]\n",
        "        Mapping from imaging channel to the corresponding\n",
        "        ``transformed_cells.xml`` file path containing CCF\n",
        "        coordinates.\n",
        "\n",
        "    channels : list[str]\n",
        "        Sorted list of available imaging channels discovered\n",
        "        for the dataset.\n",
        "\n",
        "    Methods\n",
        "   ----------\n",
        "   resolve_paths()\n",
        "        Method to get path to whole brain volume data\n",
        "\n",
        "    getCellsCCFdf(ch: list[str])\n",
        "        Retrieves and formats CCF transformed coordinates of segmented cells into a DataFrame\n",
        "\n",
        "    getcellcounts(ch: list[str])\n",
        "        Imports the cell_counts_by_region.csv\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        mouse_ID: str | int,\n",
        "        bucket: str = \"s3://aind-open-data\",\n",
        "        anon: bool = True,\n",
        "        prefer_stitched: bool = True,\n",
        "    ):\n",
        "        self.mouse_ID = str(mouse_ID)\n",
        "        self.bucket = bucket\n",
        "        self.fs = s3fs.S3FileSystem(anon=anon)\n",
        "        self.prefer_stitched = prefer_stitched\n",
        "\n",
        "        self._resolve_paths()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Path resolution\n",
        "    # ------------------------------------------------------------------\n",
        "    def _resolve_paths(self):\n",
        "      \"\"\"\n",
        "      Method to get path to whole brain volume data\n",
        "      \"\"\"\n",
        "      roots = self.fs.ls(self.bucket)\n",
        "      matches = [r for r in roots if self.mouse_ID in r]\n",
        "\n",
        "      if not matches:\n",
        "          raise FileNotFoundError(f\"No datasets found for mouse_ID {self.mouse_ID}\")\n",
        "\n",
        "      if self.prefer_stitched:\n",
        "          stitched = [r for r in matches if \"stitched\" in r.lower()]\n",
        "          if len(stitched) == 1:\n",
        "              self.rootDir = stitched[0]\n",
        "          elif len(stitched) > 1:\n",
        "              raise ValueError(f\"Multiple stitched datasets found: {stitched}\")\n",
        "          else:\n",
        "              self.rootDir = matches[0]\n",
        "      else:\n",
        "          self.rootDir = matches[0]\n",
        "\n",
        "      quant_dir = f\"{self.rootDir}/image_cell_quantification\"\n",
        "      if not self.fs.exists(quant_dir):\n",
        "          raise FileNotFoundError(\"image_cell_quantification directory not found\")\n",
        "\n",
        "      quant_paths = self.fs.glob(f\"{quant_dir}/Ex*\")\n",
        "\n",
        "      self.quantPaths = {\n",
        "          Path(p).name.split(\"_\")[1]: f\"{p}/cell_count_by_region.csv\"\n",
        "          for p in quant_paths\n",
        "      }\n",
        "      self.ccfCellsPaths = {\n",
        "          Path(p).name.split(\"_\")[1]: f\"{p}/transformed_cells.xml\"\n",
        "          for p in quant_paths\n",
        "      }\n",
        "\n",
        "      self.channels = sorted(self.quantPaths.keys())\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Cell coordinates in CCF\n",
        "    # ------------------------------------------------------------------\n",
        "    def getCellsCCFdf(self, ch: list[str]):\n",
        "        \"\"\"\n",
        "        Retrieves and formats CCF transformed coordinates of segmented cells into a DataFrame\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        ch : list[str]\n",
        "            List of imaging channels to retrieve coordinates from (e.g., [\"488\", \"561\"])\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dfs : pd.DataFrame\n",
        "            DataFrame cwhere each row is a cell and each column is a coordinate:\n",
        "            AP (anterior-posterior), DV(dorsal-ventral), ML(medial-lateral),\n",
        "            with an additional \"channel column indicating the channel of origin\n",
        "        \"\"\"\n",
        "        ccfDim = [528, 320, 456]\n",
        "        dfs = []\n",
        "\n",
        "        for channel in ch:\n",
        "            if channel not in self.ccfCellsPaths:\n",
        "                raise KeyError(f\"Channel {channel} not found\")\n",
        "\n",
        "            with self.fs.open(self.ccfCellsPaths[channel], \"rb\") as f:\n",
        "                df = pd.read_xml(\n",
        "                    f,\n",
        "                    xpath=\"//CellCounter_Marker_File//Marker_Data//Marker_Type//Marker\",\n",
        "                )\n",
        "\n",
        "            # export data in XYZ order and rename columns to AP, DV, ML\n",
        "            df = (\n",
        "                df[[\"MarkerX\", \"MarkerY\", \"MarkerZ\"]]\n",
        "                .rename(\n",
        "                    columns={\n",
        "                        \"MarkerX\": \"AP\",\n",
        "                        \"MarkerY\": \"DV\",\n",
        "                        \"MarkerZ\": \"ML\",\n",
        "                    }\n",
        "                )\n",
        "                .assign(channel=channel)\n",
        "            )\n",
        "            # Clip coordinates within specified dimensions\n",
        "            df[\"AP\"] = df[\"AP\"].clip(0, ccfDim[0] - 1)\n",
        "            df[\"DV\"] = df[\"DV\"].clip(0, ccfDim[1] - 1)\n",
        "            df[\"ML\"] = df[\"ML\"].clip(0, ccfDim[2] - 1)\n",
        "\n",
        "            dfs.append(df)\n",
        "\n",
        "        return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Cell counts by region\n",
        "    # ------------------------------------------------------------------\n",
        "    def getcellcounts(self, ch: list[str]):\n",
        "        \"\"\"\n",
        "        Imports the cell_counts_by_region.csv (quantifiction of detected cells in brain regions) as a DataFrame\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        ch : list[str]\n",
        "            List of imaging channels to retrieve coordinates from (e.g., [\"488\", \"561\"]\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dfs : pd.DataFrame\n",
        "            DataFrame where each row is a brain region cell count in a given channel\n",
        "        \"\"\"\n",
        "        required_columns = [\n",
        "            \"ID\", \"Acronym\", \"Name\", \"Struct_Info\", \"Struct_area_um3\",\n",
        "            \"Left\", \"Right\", \"Total\",\n",
        "            \"Left_Density\", \"Right_Density\", \"Total_Density\",\n",
        "        ]\n",
        "\n",
        "        # Initialize an empty list to hold DataFrames\n",
        "        cell_counts_list = []\n",
        "\n",
        "        for channel in ch:\n",
        "            if channel not in self.quantPaths:\n",
        "                raise KeyError(f\"Channel {channel} not found\")\n",
        "\n",
        "            # Load csv\n",
        "            with self.fs.open(self.quantPaths[channel], \"rb\") as f:\n",
        "                df = pd.read_csv(f)\n",
        "\n",
        "                # Check if all required columns are present\n",
        "                if set(required_columns).issubset(df.columns):\n",
        "                  # Truncate the DataFrame to specific columns\n",
        "                  cell_counts = df[required_columns]\n",
        "                  # Add a new column indicating the channel\n",
        "                  cell_counts = cell_counts.assign(channel=channel)\n",
        "                  # Append to list\n",
        "                  cell_counts_list.append(cell_counts)\n",
        "\n",
        "                # Throw error if missing columns\n",
        "                if not set(required_columns).issubset(df.columns):\n",
        "                    raise ValueError(f\"Missing required columns in {channel}\")\n",
        "\n",
        "            # Concatenate list into a single DataFrame\n",
        "            if cell_counts_list:\n",
        "              cell_counts_df = pd.concat(cell_counts_list, ignore_index=True)\n",
        "            else:\n",
        "            # return empty DataFrame if no data is found\n",
        "              cell_counts_df = pd.DataFrame(columns = required_columns + [\"channel\"])\n",
        "\n",
        "        return cell_counts_df"
      ],
      "metadata": {
        "id": "k2AylKT23sv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mouse_ID = \"689238\"\n",
        "data = load_data(mouse_ID)\n",
        "channels = data.channels\n",
        "\n",
        "ccf_df = data.getCellsCCFdf(channels)\n",
        "cell_counts_df = data.getcellcounts(channels)"
      ],
      "metadata": {
        "id": "B6tS9_Mw3yQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccf_df"
      ],
      "metadata": {
        "id": "6JTgQcgS38Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell_counts_df.channel.unique()"
      ],
      "metadata": {
        "id": "U7RNZiHUvsoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell_counts_df"
      ],
      "metadata": {
        "id": "aQNii__l4Slo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}